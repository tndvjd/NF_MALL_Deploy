"""
ë³‘ë ¬ ë²ˆì—­ ì²˜ë¦¬ ëª¨ë“ˆ
"""
import asyncio
import streamlit as st
from typing import List, Dict, Tuple
import pandas as pd
from utils.translate_simplified import translate_batch_async_with_deepl
from utils.option_translate import translate_option_column_batch

class ParallelTranslationManager:
    """ë³‘ë ¬ ë²ˆì—­ ê´€ë¦¬ì"""
    
    def __init__(self, api_key: str, batch_size: int = 5):
        self.api_key = api_key
        self.batch_size = batch_size
    
    async def translate_product_and_options_parallel(self, df: pd.DataFrame) -> pd.DataFrame:
        """ìƒí’ˆëª…ê³¼ ì˜µì…˜ì„ ë³‘ë ¬ë¡œ ë²ˆì—­"""
        
        # ë²ˆì—­í•  ì»¬ëŸ¼ë“¤ ì‹ë³„
        product_column = "ìƒí’ˆëª…" if "ìƒí’ˆëª…" in df.columns else None
        option_columns = [col for col in df.columns if 'ì˜µì…˜ì…ë ¥' in col]
        
        if not product_column and not option_columns:
            st.warning("ë²ˆì—­í•  ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return df
        
        # ë³‘ë ¬ ì‘ì—… ì¤€ë¹„
        tasks = []
        task_info = []
        
        # ìƒí’ˆëª… ë²ˆì—­ íƒœìŠ¤í¬
        if product_column:
            product_texts = df[product_column].fillna("").astype(str).tolist()
            task = translate_batch_async_with_deepl(
                product_texts, self.api_key, batch_size=self.batch_size
            )
            tasks.append(task)
            task_info.append(("product", product_column))
        
        # ì˜µì…˜ ë²ˆì—­ íƒœìŠ¤í¬ë“¤
        for col in option_columns:
            task = translate_option_column_batch(
                df, col, self.api_key, batch_size=self.batch_size, use_async=True
            )
            tasks.append(task)
            task_info.append(("option", col))
        
        # ë³‘ë ¬ ì‹¤í–‰
        st.info(f"ğŸš€ ë³‘ë ¬ ë²ˆì—­ ì‹œì‘: {len(tasks)}ê°œ ì‘ì—…")
        
        try:
            results = await asyncio.gather(*tasks)
            
            # ê²°ê³¼ ì ìš©
            df_result = df.copy()
            for i, (task_type, column) in enumerate(task_info):
                if task_type == "product":
                    df_result[column] = results[i]
                elif task_type == "option":
                    df_result[column] = results[i]
            
            st.success(f"âœ… ë³‘ë ¬ ë²ˆì—­ ì™„ë£Œ: {len(tasks)}ê°œ ì‘ì—…")
            return df_result
            
        except Exception as e:
            st.error(f"ë³‘ë ¬ ë²ˆì—­ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return df
    
    async def translate_multiple_option_columns_parallel(self, df: pd.DataFrame, 
                                                       option_columns: List[str]) -> pd.DataFrame:
        """ì—¬ëŸ¬ ì˜µì…˜ ì»¬ëŸ¼ì„ ë³‘ë ¬ë¡œ ë²ˆì—­"""
        
        if not option_columns:
            return df
        
        # ê° ì»¬ëŸ¼ë³„ ë²ˆì—­ íƒœìŠ¤í¬ ìƒì„±
        tasks = []
        for col in option_columns:
            task = translate_option_column_batch(
                df, col, self.api_key, batch_size=self.batch_size, use_async=True
            )
            tasks.append(task)
        
        st.info(f"ğŸ”„ ì˜µì…˜ ì»¬ëŸ¼ ë³‘ë ¬ ë²ˆì—­: {len(option_columns)}ê°œ ì»¬ëŸ¼")
        
        try:
            # ë³‘ë ¬ ì‹¤í–‰
            results = await asyncio.gather(*tasks)
            
            # ê²°ê³¼ ì ìš©
            df_result = df.copy()
            for i, col in enumerate(option_columns):
                df_result[col] = results[i]
            
            return df_result
            
        except Exception as e:
            st.error(f"ì˜µì…˜ ë³‘ë ¬ ë²ˆì—­ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return df

def estimate_translation_time(text_count: int, batch_size: int = 5) -> Dict[str, float]:
    """ë²ˆì—­ ì†Œìš” ì‹œê°„ ì¶”ì •"""
    
    # ê²½í—˜ì  ìˆ˜ì¹˜ (ì´ˆ ë‹¨ìœ„)
    api_call_time = 3.0  # API í˜¸ì¶œë‹¹ í‰ê·  ì‹œê°„
    batch_delay = 2.0    # ë°°ì¹˜ ê°„ ëŒ€ê¸° ì‹œê°„
    
    total_batches = (text_count + batch_size - 1) // batch_size
    estimated_time = (total_batches * api_call_time) + ((total_batches - 1) * batch_delay)
    
    return {
        'total_texts': text_count,
        'total_batches': total_batches,
        'estimated_seconds': estimated_time,
        'estimated_minutes': estimated_time / 60,
        'batch_size': batch_size
    }

def estimate_api_usage(text_count: int, avg_chars_per_text: int = 20) -> Dict[str, int]:
    """API ì‚¬ìš©ëŸ‰ ì¶”ì •"""
    
    total_chars = text_count * avg_chars_per_text
    
    return {
        'total_texts': text_count,
        'avg_chars_per_text': avg_chars_per_text,
        'estimated_total_chars': total_chars,
        'deepl_free_limit': 500000,  # 50ë§Œì
        'usage_percentage': (total_chars / 500000) * 100
    }