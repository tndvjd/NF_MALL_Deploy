"""
ê°„ì†Œí™”ëœ ë²ˆì—­ ëª¨ë“ˆ (ìºì‹œ ì œê±° ë²„ì „)
"""
import requests
import time
import asyncio
import aiohttp
import re
import pandas as pd
from typing import List, Optional, Dict
import streamlit as st

# ìƒ‰ìƒ ë²ˆì—­ ìš©ì–´ì§‘ (í•œêµ­ì–´ -> ì¼ë³¸ì–´) - ëŒ€í­ í™•ì¥
COLOR_GLOSSARY: Dict[str, str] = {
    # ê¸°ë³¸ ìƒ‰ìƒ
    "ë¹¨ê°„ìƒ‰": "ãƒ¬ãƒƒãƒ‰", "ë¹¨ê°•": "ãƒ¬ãƒƒãƒ‰", "ë ˆë“œ": "ãƒ¬ãƒƒãƒ‰", "ì ìƒ‰": "ãƒ¬ãƒƒãƒ‰",
    "íŒŒë€ìƒ‰": "ãƒ–ãƒ«ãƒ¼", "íŒŒë‘": "ãƒ–ãƒ«ãƒ¼", "ë¸”ë£¨": "ãƒ–ãƒ«ãƒ¼", "ì²­ìƒ‰": "ãƒ–ãƒ«ãƒ¼",
    "ë…¸ë€ìƒ‰": "ã‚¤ã‚¨ãƒ­ãƒ¼", "ë…¸ë‘": "ã‚¤ã‚¨ãƒ­ãƒ¼", "ì˜ë¡œìš°": "ã‚¤ã‚¨ãƒ­ãƒ¼", "í™©ìƒ‰": "ã‚¤ã‚¨ãƒ­ãƒ¼",
    "ì´ˆë¡ìƒ‰": "ã‚°ãƒªãƒ¼ãƒ³", "ì´ˆë¡": "ã‚°ãƒªãƒ¼ãƒ³", "ë…¹ìƒ‰": "ã‚°ãƒªãƒ¼ãƒ³", "ê·¸ë¦°": "ã‚°ãƒªãƒ¼ãƒ³",
    "ë³´ë¼ìƒ‰": "ãƒ‘ãƒ¼ãƒ—ãƒ«", "ë³´ë¼": "ãƒ‘ãƒ¼ãƒ—ãƒ«", "í¼í”Œ": "ãƒ‘ãƒ¼ãƒ—ãƒ«", "ìì£¼ìƒ‰": "ãƒ‘ãƒ¼ãƒ—ãƒ«",
    "ì£¼í™©ìƒ‰": "ã‚ªãƒ¬ãƒ³ã‚¸", "ì£¼í™©": "ã‚ªãƒ¬ãƒ³ã‚¸", "ì˜¤ë Œì§€": "ã‚ªãƒ¬ãƒ³ã‚¸",
    "ë¶„í™ìƒ‰": "ãƒ”ãƒ³ã‚¯", "ë¶„í™": "ãƒ”ãƒ³ã‚¯", "í•‘í¬": "ãƒ”ãƒ³ã‚¯",
    
    # ë¬´ì±„ìƒ‰
    "ê²€ì€ìƒ‰": "ãƒ–ãƒ©ãƒƒã‚¯", "ê²€ì •": "ãƒ–ãƒ©ãƒƒã‚¯", "ë¸”ë™": "ãƒ–ãƒ©ãƒƒã‚¯", "í‘ìƒ‰": "ãƒ–ãƒ©ãƒƒã‚¯",
    "í•˜ì–€ìƒ‰": "ãƒ›ãƒ¯ã‚¤ãƒˆ", "í•˜ì–‘": "ãƒ›ãƒ¯ã‚¤ãƒˆ", "í™”ì´íŠ¸": "ãƒ›ãƒ¯ã‚¤ãƒˆ", "ë°±ìƒ‰": "ãƒ›ãƒ¯ã‚¤ãƒˆ",
    "íšŒìƒ‰": "ã‚°ãƒ¬ãƒ¼", "ê·¸ë ˆì´": "ã‚°ãƒ¬ãƒ¼", "íšŒë°±ìƒ‰": "ã‚°ãƒ¬ãƒ¼",
    
    # ê³ ê¸‰ ìƒ‰ìƒ
    "ë² ì´ì§€": "ãƒ™ãƒ¼ã‚¸ãƒ¥", "ì•„ì´ë³´ë¦¬": "ã‚¢ã‚¤ãƒœãƒªãƒ¼", "í¬ë¦¼": "ã‚¯ãƒªãƒ¼ãƒ ",
    "ë„¤ì´ë¹„": "ãƒã‚¤ãƒ“ãƒ¼", "ë‚¨ìƒ‰": "ãƒã‚¤ãƒ“ãƒ¼", "ê°ì²­ìƒ‰": "ãƒã‚¤ãƒ“ãƒ¼",
    "ì¹´í‚¤": "ã‚«ãƒ¼ã‚­", "ì˜¬ë¦¬ë¸Œ": "ã‚ªãƒªãƒ¼ãƒ–", "ë¯¼íŠ¸": "ãƒŸãƒ³ãƒˆ",
    "ë¼ë²¤ë”": "ãƒ©ãƒ™ãƒ³ãƒ€ãƒ¼", "ë°”ì´ì˜¬ë ›": "ãƒã‚¤ã‚ªãƒ¬ãƒƒãƒˆ",
    "ë§ˆì  íƒ€": "ãƒã‚¼ãƒ³ã‚¿", "ì‹œì•ˆ": "ã‚·ã‚¢ãƒ³", "í„°ì½°ì´ì¦ˆ": "ã‚¿ãƒ¼ã‚³ã‚¤ã‚º",
    
    # ë¸Œë¼ìš´ ê³„ì—´
    "ê°ˆìƒ‰": "ãƒ–ãƒ©ã‚¦ãƒ³", "ë¸Œë¼ìš´": "ãƒ–ãƒ©ã‚¦ãƒ³", "ë°¤ìƒ‰": "ãƒ–ãƒ©ã‚¦ãƒ³",
    "ì´ˆì½œë¦¿": "ãƒãƒ§ã‚³ãƒ¬ãƒ¼ãƒˆ", "ì»¤í”¼": "ã‚³ãƒ¼ãƒ’ãƒ¼", "ëª¨ì¹´": "ãƒ¢ã‚«",
    "ì¹´ë©œ": "ã‚­ãƒ£ãƒ¡ãƒ«", "íƒ€ë°”ì½”": "ã‚¿ãƒã‚³",
    
    # ê³¨ë“œ/ì‹¤ë²„ ê³„ì—´
    "ê¸ˆìƒ‰": "ã‚´ãƒ¼ãƒ«ãƒ‰", "ê³¨ë“œ": "ã‚´ãƒ¼ãƒ«ãƒ‰", "í™©ê¸ˆìƒ‰": "ã‚´ãƒ¼ãƒ«ãƒ‰",
    "ì€ìƒ‰": "ã‚·ãƒ«ãƒãƒ¼", "ì‹¤ë²„": "ã‚·ãƒ«ãƒãƒ¼", "ë°±ê¸ˆìƒ‰": "ãƒ—ãƒ©ãƒãƒŠ",
    
    # ëª©ì¬/ê°€êµ¬ ìƒ‰ìƒ (ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ì¶”ê°€)
    "ì˜¤í¬": "ã‚ªãƒ¼ã‚¯", "ë©”ì´í”Œ": "ãƒ¡ãƒ¼ãƒ—ãƒ«", "ì•„ì¹´ì‹œì•„": "ã‚¢ã‚«ã‚·ã‚¢",
    "ì›”ë„›": "ã‚¦ã‚©ãƒ«ãƒŠãƒƒãƒˆ", "ë©€ë°”ìš°": "ãƒ¡ãƒ«ãƒã‚¦", "ì—˜ë‹¤": "ã‚¨ãƒ«ãƒ€ãƒ¼",
    "ê³ ë¬´ë‚˜ë¬´": "ã‚´ãƒ ãƒã‚­", "ì‚¼ë‚˜ë¬´": "ã‚¹ã‚®", "ì°¸ì£½": "ãƒãƒ£ãƒ³ãƒãƒ¥ãƒ³",
    "ë‚´ì¶”ëŸ´": "ãƒŠãƒãƒ¥ãƒ©ãƒ«", "ë„¤ì¶”ëŸ´": "ãƒŠãƒãƒ¥ãƒ©ãƒ«", "ì›Œì‹œ": "ã‚¦ã‚©ãƒƒã‚·ãƒ¥",
    "ë¹ˆí‹°ì§€": "ãƒ´ã‚£ãƒ³ãƒ†ãƒ¼ã‚¸", "ì—”í‹±": "ã‚¢ãƒ³ãƒ†ã‚£ãƒ¼ã‚¯", "ìš°ë“œ": "ã‚¦ãƒƒãƒ‰",
    "ì• ì‰¬": "ã‚¢ãƒƒã‚·ãƒ¥", "ìƒˆí‹´": "ã‚µãƒ†ãƒ³", "ë§ˆë¸”": "ãƒãƒ¼ãƒ–ãƒ«",
    "ì„¸ë¼ë¯¹": "ã‚»ãƒ©ãƒŸãƒƒã‚¯", "í¸ë°±": "ãƒ’ãƒã‚­", "ìì‘ë‚˜ë¬´": "ã‚·ãƒ©ã‚«ãƒ",
    
    # ìƒ‰ìƒ ìˆ˜ì‹ì–´
    "ì—°ê·¸ë ˆì´": "ãƒ©ã‚¤ãƒˆã‚°ãƒ¬ãƒ¼", "ì§„ê·¸ë ˆì´": "ãƒ€ãƒ¼ã‚¯ã‚°ãƒ¬ãƒ¼", "ë¬´ë“œë¸”ë™": "ãƒ ãƒ¼ãƒ‰ãƒ–ãƒ©ãƒƒã‚¯",
    "ìŠ¤ì¹´ì´ë¸”ë£¨": "ã‚¹ã‚«ã‚¤ãƒ–ãƒ«ãƒ¼", "ë² ì´ë¹„í•‘í¬": "ãƒ™ãƒ“ãƒ¼ãƒ”ãƒ³ã‚¯", "ë¡œì¦ˆê³¨ë“œ": "ãƒ­ãƒ¼ã‚ºã‚´ãƒ¼ãƒ«ãƒ‰",
    "íŒŒìš°ë”ë¸”ë£¨": "ãƒ‘ã‚¦ãƒ€ãƒ¼ãƒ–ãƒ«ãƒ¼", "ëª¨ë‹ë¸”ë£¨": "ãƒ¢ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ–ãƒ«ãƒ¼", "í‹¸ë¸”ë£¨": "ãƒ†ã‚£ãƒ¼ãƒ«ãƒ–ãƒ«ãƒ¼",
    "ìƒŒë“œë² ì´ì§€": "ã‚µãƒ³ãƒ‰ãƒ™ãƒ¼ã‚¸ãƒ¥", "ìƒŒë“œê·¸ë ˆì´": "ã‚µãƒ³ãƒ‰ã‚°ãƒ¬ãƒ¼", "ë©”íƒˆê·¸ë ˆì´": "ãƒ¡ã‚¿ãƒ«ã‚°ãƒ¬ãƒ¼",
    "ë°”ìƒ¬íŠ¸ê·¸ë ˆì´": "ãƒã‚µãƒ«ãƒˆã‚°ãƒ¬ãƒ¼", "ìƒˆí‹´ê·¸ë ˆì´": "ã‚µãƒ†ãƒ³ã‚°ãƒ¬ãƒ¼", "ë¹ˆí‹°ì§€ê·¸ë ˆì´": "ãƒ´ã‚£ãƒ³ãƒ†ãƒ¼ã‚¸ã‚°ãƒ¬ãƒ¼",
    "ì›œê·¸ë ˆì´": "ã‚¦ã‚©ãƒ¼ãƒ ã‚°ãƒ¬ãƒ¼", "ì°¨ì½œê·¸ë ˆì´": "ãƒãƒ£ã‚³ãƒ¼ãƒ«ã‚°ãƒ¬ãƒ¼", "ì—°í•‘í¬": "ãƒ©ã‚¤ãƒˆãƒ”ãƒ³ã‚¯",
    "ì¸ë””í•‘í¬": "ã‚¤ãƒ³ãƒ‡ã‚£ãƒ”ãƒ³ã‚¯", "ë¡œíˆ¬ã‚¹í•‘í¬": "ãƒ­ãƒ¼ã‚¿ã‚¹ãƒ”ãƒ³ã‚¯", "ì˜¬ë¦¬ë¸Œê·¸ë¦°": "ã‚ªãƒªãƒ¼ãƒ–ã‚°ãƒªãƒ¼ãƒ³",
    "í¬ë ˆã‚¹íŠ¸ê·¸ë¦°": "ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã‚°ãƒªãƒ¼ãƒ³", "ë¯¼íŠ¸ê·¸ë¦°": "ãƒŸãƒ³ãƒˆã‚°ãƒªãƒ¼ãƒ³", "í‹¸ê·¸ë¦°": "ãƒ†ã‚£ãƒ¼ãƒ«ã‚°ãƒªãƒ¼ãƒ³",
    "ìŠ¤ëª¨í‚¤ì˜¬ë¦¬ë¸´": "ã‚¹ãƒ¢ãƒ¼ã‚­ãƒ¼ã‚ªãƒªãƒ¼ãƒ–", "ë²„í„°ì˜ë¡œìš°": "ãƒã‚¿ãƒ¼ã‚¤ã‚¨ãƒ­ãƒ¼", "ì—°ë…¸ë‘": "ãƒ©ã‚¤ãƒˆã‚¤ã‚¨ãƒ­ãƒ¼",
    
    # ë³µí•© ìƒ‰ìƒ (ê³ ë¹ˆë„)
    "ìˆœë°±ìƒ‰": "ç´”ç™½", "ìœ ë°±": "ä¹³ç™½", "ë²„í„°": "ãƒã‚¿ãƒ¼", "ìºëŸ¿": "ã‚­ãƒ£ãƒ­ãƒƒãƒˆ",
    "ì–´í”„ë¦¬ì½§": "ã‚¢ãƒ—ãƒªã‚³ãƒƒãƒˆ", "í”¼ì¹˜": "ãƒ”ãƒ¼ãƒ", "ì½”ë„": "ã‚³ãƒ¼ãƒ©ãƒ«", "ì™€ì¸": "ãƒ¯ã‚¤ãƒ³",
    "ë²„ê±´ë””": "ãƒãƒ¼ã‚¬ãƒ³ãƒ‡ã‚£", "ë¨¸ìŠ¤íƒ€ë“œ": "ãƒã‚¹ã‚¿ãƒ¼ãƒ‰", "ë°”ë‹ë¼": "ãƒãƒ‹ãƒ©",
    "ë ˆëª¬": "ãƒ¬ãƒ¢ãƒ³", "ì²­ë¡": "ã‚¿ãƒ¼ã‚³ã‚¤ã‚º", "ìŠ¤ì¹´ì´": "ã‚¹ã‚«ã‚¤", "ë¸”ë£¨ë² ë¦¬": "ãƒ–ãƒ«ãƒ¼ãƒ™ãƒªãƒ¼",
    
    # íŠ¹ìˆ˜ ìƒ‰ìƒ
    "íˆ¬ëª…": "é€æ˜", "í´ë¦¬ì–´": "ã‚¯ãƒªã‚¢", "ë§¤íŠ¸": "ãƒãƒƒãƒˆ", "ë©”íƒˆ": "ãƒ¡ã‚¿ãƒ«",
    "ê¸€ë¡œì‹œ": "ã‚°ãƒ­ãƒƒã‚·ãƒ¼", "ë©”íƒˆë¦­": "ãƒ¡ã‚¿ãƒªãƒƒã‚¯", "ìƒˆí‹´": "ã‚µãƒ†ãƒ³",
    "ëŒ€ë¦¬ì„": "å¤§ç†çŸ³", "ì›ëª©": "ç„¡å¢æ", "íˆ¬í†¤": "ãƒ„ãƒ¼ãƒˆãƒ³",
    
    # íŒ¨í„´/ì§ˆê°
    "ë¬´ëŠ¬": "æŸ„", "íŒ¨í„´": "ãƒ‘ã‚¿ãƒ¼ãƒ³", "ìŠ¤íŠ¸ë¼ì´í”„": "ã‚¹ãƒˆãƒ©ã‚¤ãƒ—",
    "ì²´í¬": "ãƒã‚§ãƒƒã‚¯", "ë„íŠ¸": "ãƒ‰ãƒƒãƒˆ", "í”Œë¼ì›Œ": "ãƒ•ãƒ©ãƒ¯ãƒ¼",
    
    # ìì£¼ ì‚¬ìš©ë˜ëŠ” ë³µí•© ìƒ‰ìƒë“¤ ì¶”ê°€ (ë¯¸ë²ˆì—­ ë¬¸ì œ í•´ê²°ìš©)
    "ì˜¤í¬í™”ì´íŠ¸": "ã‚ªãƒ¼ã‚¯ãƒ›ãƒ¯ã‚¤ãƒˆ", "í¬ë¦¼í™”ì´íŠ¸": "ã‚¯ãƒªãƒ¼ãƒ ãƒ›ãƒ¯ã‚¤ãƒˆ",
    "ë„¤ì¶”ëŸ´í”¼ì¹˜": "ãƒŠãƒãƒ¥ãƒ©ãƒ«ãƒ”ãƒ¼ãƒ", "ë„¤ì¶”ëŸ´ë¸”ë£¨": "ãƒŠãƒãƒ¥ãƒ©ãƒ«ãƒ–ãƒ«ãƒ¼",
    "ë„¤ì¶”ëŸ´ë©€ë°”ìš°": "ãƒŠãƒãƒ¥ãƒ©ãƒ«ãƒ¡ãƒ«ãƒã‚¦", "ë„¤ì¶”ëŸ´í™”ì´íŠ¸": "ãƒŠãƒãƒ¥ãƒ©ãƒ«ãƒ›ãƒ¯ã‚¤ãƒˆ",
    "í™”ì´íŠ¸ë©”ì´í”Œ": "ãƒ›ãƒ¯ã‚¤ãƒˆãƒ¡ãƒ¼ãƒ—ãƒ«", "í™”ì´íŠ¸ê·¸ë ˆì´": "ãƒ›ãƒ¯ã‚¤ãƒˆã‚°ãƒ¬ãƒ¼",
    "í™”ì´íŠ¸ì˜¤í¬": "ãƒ›ãƒ¯ã‚¤ãƒˆã‚ªãƒ¼ã‚¯", "ë‹¤í¬ë¸Œë¼ìš´": "ãƒ€ãƒ¼ã‚¯ãƒ–ãƒ©ã‚¦ãƒ³",
    "ë¼ì´íŠ¸ë¸Œë¼ìš´": "ãƒ©ã‚¤ãƒˆãƒ–ãƒ©ã‚¦ãƒ³", "ë”¥ë¸Œë¼ìš´": "ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ–ãƒ©ã‚¦ãƒ³",
    "ê·¸ë ˆì´ë¸”ë™": "ã‚°ãƒ¬ãƒ¼ãƒ–ãƒ©ãƒƒã‚¯", "ëª¨ì¹´ë¸Œë¼ìš´": "ãƒ¢ã‚«ãƒ–ãƒ©ã‚¦ãƒ³",
    "ì•„ì´ë³´ë¦¬ë©”ì´í”Œ": "ã‚¢ã‚¤ãƒœãƒªãƒ¼ãƒ¡ãƒ¼ãƒ—ãƒ«", "ì›Œì‹œê·¸ë¦°": "ã‚¦ã‚©ãƒƒã‚·ãƒ¥ã‚°ãƒªãƒ¼ãƒ³",
    "ë¸”ë™ì•„ì¹´ì‹œì•„": "ãƒ–ãƒ©ãƒƒã‚¯ã‚¢ã‚«ã‚·ã‚¢", "ê·¸ë ˆì´ë©”ì´í”Œ": "ã‚°ãƒ¬ãƒ¼ãƒ¡ãƒ¼ãƒ—ãƒ«",
    "ë² ì´ì§€ë¸Œë¼ìš´": "ãƒ™ãƒ¼ã‚¸ãƒ¥ãƒ–ãƒ©ã‚¦ãƒ³", "ë¼ì´íŠ¸ê·¸ë ˆì´": "ãƒ©ã‚¤ãƒˆã‚°ãƒ¬ãƒ¼",
    "í˜ì¼ê·¸ë ˆì´": "ãƒšãƒ¼ãƒ«ã‚°ãƒ¬ãƒ¼", "ë‹¤í¬ê·¸ë ˆì´": "ãƒ€ãƒ¼ã‚¯ã‚°ãƒ¬ãƒ¼",
    "ì—°íšŒìƒ‰": "ãƒ©ã‚¤ãƒˆã‚°ãƒ¬ãƒ¼", "ì°¨ì½œë¸”ë™": "ãƒãƒ£ã‚³ãƒ¼ãƒ«ãƒ–ãƒ©ãƒƒã‚¯",
    "ë¬´ê´‘ì‹¤ë²„": "ãƒãƒƒãƒˆã‚·ãƒ«ãƒãƒ¼", "ìœ ê´‘ì‹¤ë²„": "ã‚°ãƒ­ãƒƒã‚·ãƒ¼ã‚·ãƒ«ãƒãƒ¼"
}

def preprocess_text(text: str) -> str:
    """ë²ˆì—­ ì „ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
    if not text or not isinstance(text, str):
        return ""
    
    # ê¸°ë³¸ ì •ë¦¬
    text = text.strip()
    
    # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ í†µí•©
    text = re.sub(r'\s+', ' ', text)
    
    return text

def validate_deepl_api_key(api_key: str) -> bool:
    """DeepL API í‚¤ ìœ íš¨ì„± ê²€ì¦"""
    if not api_key or not api_key.strip():
        st.error("API í‚¤ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    
    # API í‚¤ í˜•ì‹ ê²€ì¦ (DeepL API í‚¤ëŠ” ë³´í†µ UUID í˜•íƒœ)
    if len(api_key.strip()) < 20:
        st.error("API í‚¤ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. DeepL API í‚¤ëŠ” ìµœì†Œ 20ì ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
        return False
    
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë²ˆì—­ìœ¼ë¡œ API í‚¤ ê²€ì¦
    test_url = "https://api-free.deepl.com/v2/translate"
    test_data = {
        'auth_key': api_key.strip(),
        'text': 'test',
        'target_lang': 'JA'
    }
    
    try:
        response = requests.post(test_url, data=test_data, timeout=10)
        
        if response.status_code == 403:
            st.error("API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.")
            st.error("DeepL ê³„ì •ì—ì„œ API í‚¤ë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return False
        elif response.status_code == 456:
            st.error("API ì‚¬ìš©ëŸ‰ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.")
            return False
        elif response.status_code == 200:
            st.success("âœ… API í‚¤ê°€ ìœ íš¨í•©ë‹ˆë‹¤.")
            return True
        else:
            st.warning(f"API ì‘ë‹µ ì½”ë“œ: {response.status_code}")
            return False
            
    except requests.exceptions.RequestException as e:
        st.error(f"API í‚¤ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False
    
    return False

def translate_with_deepl(text: str, api_key: str, target_lang: str = 'JA') -> Optional[str]:
    """DeepL APIë¥¼ ì‚¬ìš©í•œ ë‹¨ì¼ í…ìŠ¤íŠ¸ ë²ˆì—­"""
    if not text or not text.strip():
        return ""
    
    preprocessed_text = preprocess_text(text)
    if not preprocessed_text:
        return ""
    
    url = "https://api-free.deepl.com/v2/translate"
    
    data = {
        'auth_key': api_key,
        'text': preprocessed_text,
        'target_lang': target_lang,
        'preserve_formatting': '1'
    }
    
    try:
        response = requests.post(url, data=data, timeout=10)  # íƒ€ì„ì•„ì›ƒ ë‹¨ì¶•
        
        # 403 ì—ëŸ¬ì— ëŒ€í•œ ê°„ë‹¨í•œ ì²˜ë¦¬
        if response.status_code == 403:
            print(f"ë²ˆì—­ API ì˜¤ë¥˜: 403 Forbidden - {preprocessed_text}")
            return None
        
        if response.status_code == 200:
            result = response.json()
            if 'translations' in result and result['translations']:
                return result['translations'][0]['text']
        
        print(f"ë²ˆì—­ API ì‘ë‹µ ì½”ë“œ: {response.status_code}")
        return None
        
    except requests.exceptions.Timeout:
        print(f"ë²ˆì—­ API íƒ€ì„ì•„ì›ƒ: {preprocessed_text}")
        return None
    except requests.exceptions.RequestException as e:
        print(f"ë²ˆì—­ API ì˜¤ë¥˜: {str(e)}")
        return None
    except Exception as e:
        print(f"ë²ˆì—­ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return None

def translate_batch_with_deepl(texts: List[str], api_key: str, target_lang: str = 'JA', 
                              batch_size: int = 5) -> List[str]:
    """ë°°ì¹˜ ë²ˆì—­ (ë™ê¸° ë°©ì‹)"""
    if not texts:
        return []
    
    translated_texts = [""] * len(texts)
    
    # ì§„í–‰ë¥  í‘œì‹œ
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    total_batches = (len(texts) + batch_size - 1) // batch_size
    
    for batch_idx in range(0, len(texts), batch_size):
        batch_texts = texts[batch_idx:batch_idx + batch_size]
        batch_translations = []
        
        for text in batch_texts:
            translation = translate_with_deepl(text, api_key, target_lang)
            batch_translations.append(translation if translation else "")
            time.sleep(2.0)  # API í˜¸ì¶œ ê°„ê²© (429 ì—ëŸ¬ ë°©ì§€)
        
        # ê²°ê³¼ ì €ì¥
        for i, translation in enumerate(batch_translations):
            translated_texts[batch_idx + i] = translation
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        current_batch = (batch_idx // batch_size) + 1
        progress = current_batch / total_batches
        progress_bar.progress(progress)
        status_text.text(f"ë²ˆì—­ ì§„í–‰: {current_batch}/{total_batches} ë°°ì¹˜ ì™„ë£Œ")
    
    progress_bar.empty()
    status_text.empty()
    
    return translated_texts

async def translate_batch_async_with_deepl(texts: List[str], api_key: str, 
                                         target_lang: str = 'JA', 
                                         batch_size: int = 5) -> List[str]:
    """ë°°ì¹˜ ë²ˆì—­ (ë¹„ë™ê¸° ë°©ì‹) - ì¤‘ë³µ ì œê±° ë° ìºì‹± ìµœì í™”"""
    if not texts:
        return []
    
    from utils.translation_cache import get_translation_cache
    cache = get_translation_cache()
    
    # 1ë‹¨ê³„: ìºì‹œì—ì„œ ê¸°ì¡´ ë²ˆì—­ ì¡°íšŒ ë° ì¤‘ë³µ ì œê±°
    unique_texts = []
    text_to_indices = {}  # ê° ê³ ìœ  í…ìŠ¤íŠ¸ê°€ ì›ë³¸ ë¦¬ìŠ¤íŠ¸ì˜ ì–´ëŠ ìœ„ì¹˜ì— ìˆëŠ”ì§€ ë§¤í•‘
    translated_texts = [""] * len(texts)
    
    for i, text in enumerate(texts):
        if not text or not text.strip():
            translated_texts[i] = text
            continue
        
        # ìºì‹œ ì¡°íšŒ
        cached_result = cache.get(text, target_lang)
        if cached_result is not None:
            translated_texts[i] = cached_result
            continue
        
        # ì¤‘ë³µ ì œê±°
        if text not in text_to_indices:
            text_to_indices[text] = []
            unique_texts.append(text)
        text_to_indices[text].append(i)
    
    if not unique_texts:
        return translated_texts
    
    st.info(f"ğŸ”„ ì¤‘ë³µ ì œê±°: {len(texts)}ê°œ â†’ {len(unique_texts)}ê°œ (ìºì‹œ ì ì¤‘: {len(texts) - len(unique_texts) - sum(len(indices) for indices in text_to_indices.values())}ê°œ)")
    
    # ì§„í–‰ë¥  í‘œì‹œ
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    async def translate_single_async(session, text: str) -> str:
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ ë¹„ë™ê¸° ë²ˆì—­"""
        if not text or not text.strip():
            return ""
        
        preprocessed_text = preprocess_text(text)
        if not preprocessed_text:
            return ""
        
        url = "https://api-free.deepl.com/v2/translate"
        data = {
            'auth_key': api_key,
            'text': preprocessed_text,
            'target_lang': target_lang,
            'preserve_formatting': '1'
        }
        
        try:
            async with session.post(url, data=data, timeout=15) as response:  # íƒ€ì„ì•„ì›ƒ ì¦ê°€
                if response.status == 200:
                    result = await response.json()
                    if 'translations' in result and result['translations']:
                        translated_text = result['translations'][0]['text']
                        if translated_text and translated_text.strip():
                            return translated_text
                        else:
                            print(f"ë¹ˆ ë²ˆì—­ ê²°ê³¼: '{preprocessed_text}' -> '{translated_text}'")
                            return ""
                elif response.status == 403:
                    print(f"403 Forbidden: '{preprocessed_text}'")
                    return ""
                else:
                    print(f"API ì‘ë‹µ ì½”ë“œ {response.status}: '{preprocessed_text}'")
                    return ""
        except asyncio.TimeoutError:
            print(f"íƒ€ì„ì•„ì›ƒ: '{preprocessed_text}'")
            return ""
        except Exception as e:
            print(f"ë¹„ë™ê¸° ë²ˆì—­ ì˜¤ë¥˜ '{preprocessed_text}': {str(e)}")
            return ""
        
        return ""
    
    # ë¹„ë™ê¸° ì²˜ë¦¬
    async with aiohttp.ClientSession() as session:
        total_batches = (len(texts) + batch_size - 1) // batch_size
        
        for batch_idx in range(0, len(texts), batch_size):
            batch_texts = texts[batch_idx:batch_idx + batch_size]
            
            # ë°°ì¹˜ ë‚´ ë¹„ë™ê¸° ì²˜ë¦¬
            tasks = [translate_single_async(session, text) for text in batch_texts]
            batch_translations = await asyncio.gather(*tasks)
            
            # ê²°ê³¼ ì €ì¥
            for i, translation in enumerate(batch_translations):
                translated_texts[batch_idx + i] = translation
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            current_batch = (batch_idx // batch_size) + 1
            progress = current_batch / total_batches
            progress_bar.progress(progress)
            status_text.text(f"ë²ˆì—­ ì§„í–‰: {current_batch}/{total_batches} ë°°ì¹˜ ì™„ë£Œ")
            
            # API í˜¸ì¶œ ê°„ê²© (429 ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ ì¦ê°€)
            await asyncio.sleep(2.0)  # 2ì´ˆë¡œ ì¦ê°€
    
    progress_bar.empty()
    status_text.empty()
    
    return translated_texts

# ê¸°ì¡´ í•¨ìˆ˜ë“¤ê³¼ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ í•¨ìˆ˜ë“¤
async def translate_product_names(df, target_column: str, api_key: str, 
                                batch_size: int = 5, use_async: bool = True):
    """ìƒí’ˆëª… ë²ˆì—­ (ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜)"""
    texts = df[target_column].fillna("").astype(str).tolist()
    
    if use_async:
        return await translate_batch_async_with_deepl(texts, api_key, batch_size=batch_size)
    else:
        return translate_batch_with_deepl(texts, api_key, batch_size=batch_size)

def translate_color_with_glossary(color: str, api_key: str, target_lang: str = 'JA') -> str:
    """ìš©ì–´ì§‘ì„ í™œìš©í•œ ìƒ‰ìƒ ë²ˆì—­ (ê°„ì†Œí™”ëœ ë²„ì „)"""
    if not color or not color.strip():
        return color
    
    color = color.strip()
    color_lower = color.lower()
    
    # 1ë‹¨ê³„: ì •í™•í•œ ë§¤ì¹­ ìš°ì„ 
    if color_lower in COLOR_GLOSSARY:
        return COLOR_GLOSSARY[color_lower]
    
    # 2ë‹¨ê³„: ë¶€ë¶„ ë§¤ì¹­ (ê°„ì†Œí™”)
    for korean, japanese in COLOR_GLOSSARY.items():
        if korean.lower() in color_lower:
            return japanese
    
    # 3ë‹¨ê³„: DeepL API ì‚¬ìš© (ìš©ì–´ì§‘ì— ì—†ëŠ” ê²½ìš°ë§Œ)
    try:
        translated = translate_with_deepl(color, api_key, target_lang)
        return translated if translated else color
    except:
        return color

def translate_option_colors(option_text: str, api_key: str, target_lang: str = 'JA') -> str:
    """ì˜µì…˜ ìƒ‰ìƒ ë²ˆì—­ (ê°œì„ ëœ ë²„ì „)"""
    if not option_text or not isinstance(option_text, str):
        return option_text
    
    # ìƒ‰ìƒ{...} í˜•ì‹ íŒŒì‹±
    match = re.match(r'ìƒ‰ìƒ\{([^}]+)\}', option_text)
    if not match:
        return option_text
    
    colors = match.group(1).split('|')
    translated_colors = []
    
    for color in colors:
        color = color.strip()
        if color:
            # ê°œì„ ëœ ìƒ‰ìƒ ë²ˆì—­ ì‚¬ìš©
            translated = translate_color_with_glossary(color, api_key, target_lang)
            translated_colors.append(translated)
    
    return f"ìƒ‰ìƒ{{{'|'.join(translated_colors)}}}"

def analyze_colors_in_data(df, option_columns: List[str] = None) -> Dict:
    """ë°ì´í„°ì—ì„œ ìƒ‰ìƒ ë¶„ì„"""
    import pandas as pd
    from collections import Counter
    
    if option_columns is None:
        option_columns = [col for col in df.columns if 'ì˜µì…˜ì…ë ¥' in col]
    
    all_colors = []
    color_stats = {}
    
    for col in option_columns:
        if col not in df.columns:
            continue
            
        col_colors = []
        for option_text in df[col].fillna(""):
            if not isinstance(option_text, str):
                continue
                
            # ìƒ‰ìƒ{...} í˜•ì‹ íŒŒì‹±
            match = re.match(r'ìƒ‰ìƒ\{([^}]+)\}', option_text)
            if match:
                colors = [c.strip() for c in match.group(1).split('|') if c.strip()]
                col_colors.extend(colors)
                all_colors.extend(colors)
        
        color_stats[col] = Counter(col_colors)
    
    # ì „ì²´ ìƒ‰ìƒ í†µê³„
    total_color_counter = Counter(all_colors)
    
    # ìš©ì–´ì§‘ì— ìˆëŠ” ìƒ‰ìƒê³¼ ì—†ëŠ” ìƒ‰ìƒ ë¶„ë¥˜
    colors_in_glossary = []
    colors_not_in_glossary = []
    
    for color, count in total_color_counter.items():
        found_in_glossary = False
        color_lower = color.lower()
        
        # ì •í™•í•œ ë§¤ì¹­ ìš°ì„ 
        if color_lower in COLOR_GLOSSARY:
            colors_in_glossary.append((color, count, COLOR_GLOSSARY[color_lower]))
            found_in_glossary = True
        else:
            # ë³µí•© ìƒ‰ìƒ ë§¤ì¹­ (ê¸¸ì´ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê¸´ ë§¤ì¹­ ìš°ì„ )
            sorted_glossary = sorted(COLOR_GLOSSARY.items(), key=lambda x: len(x[0]), reverse=True)
            
            for korean_color, japanese_color in sorted_glossary:
                korean_lower = korean_color.lower()
                
                # ì •í™•í•œ ë‹¨ì–´ ê²½ê³„ ë§¤ì¹­
                if korean_lower == color_lower:
                    colors_in_glossary.append((color, count, japanese_color))
                    found_in_glossary = True
                    break
                
                # ë³µí•© ìƒ‰ìƒ ì²´í¬ (ìˆ˜ì‹ì–´ + ê¸°ë³¸ìƒ‰ìƒ)
                modifiers = ["ë‹¤í¬", "ë¼ì´íŠ¸", "ë”¥", "ì†Œí”„íŠ¸", "í¬ë¦¼", "ë©”ì´í”Œ", "ì•„ì´ìŠ¤", "í„", "ë§¤íŠ¸",
                            "ì˜¤í¬", "ì•„ì¹´ì‹œì•„", "ì›”ë„›", "ë©€ë°”ìš°", "ì—˜ë‹¤", "ê³ ë¬´ë‚˜ë¬´", "ì‚¼ë‚˜ë¬´", "ì°¸ì£½",
                            "ë‚´ì¶”ëŸ´", "ë„¤ì¶”ëŸ´", "ì›Œì‹œ", "ë¹ˆí‹°ì§€", "ì—”í‹±", "ìš°ë“œ", "ì• ì‰¬", "ìƒˆí‹´", "ë§ˆë¸”",
                            "ë ˆë“œíŒŒì¸", "ì§„", "ì—°", "ì˜¬", "ë¬´ë“œ", "ë¸”ë™", "ìŠ¤ì¹´ì´", "ë² ì´ë¹„", "ë¡œì¦ˆ",
                            "íŒŒìš°ë”", "ëª¨ë‹", "í‹¸", "ìƒŒë“œ", "ë©”íƒˆ", "ë°”ìƒ¬íŠ¸", "ì›œ", "ì°¨ì½œ", "ì¸ë””",
                            "ë¡œíˆ¬ìŠ¤", "ìŠ¤ëª¨í‚¤", "ë²„í„°", "ìˆœë°±", "ìœ ë°±"]
                for modifier in modifiers:
                    if (color_lower.startswith(modifier) and color_lower.endswith(korean_lower)) or \
                       (color_lower.endswith(modifier) and color_lower.startswith(korean_lower)):
                        modifier_jp = {
                            "ë‹¤í¬": "ãƒ€ãƒ¼ã‚¯", "ë¼ì´íŠ¸": "ãƒ©ã‚¤ãƒˆ", "ë”¥": "ãƒ‡ã‚£ãƒ¼ãƒ—", 
                            "ì†Œí”„íŠ¸": "ã‚½ãƒ•ãƒˆ", "í¬ë¦¼": "ã‚¯ãƒªãƒ¼ãƒ ", "ë©”ì´í”Œ": "ãƒ¡ãƒ¼ãƒ—ãƒ«",
                            "ì•„ì´ìŠ¤": "ã‚¢ã‚¤ã‚¹", "í„": "ãƒ‘ãƒ¼ãƒ«", "ë§¤íŠ¸": "ãƒãƒƒãƒˆ",
                            "ì˜¤í¬": "ã‚ªãƒ¼ã‚¯", "ì•„ì¹´ì‹œì•„": "ã‚¢ã‚«ã‚·ã‚¢", "ì›”ë„›": "ã‚¦ã‚©ãƒ«ãƒŠãƒƒãƒˆ",
                            "ë©€ë°”ìš°": "ãƒ¡ãƒ«ãƒã‚¦", "ì—˜ë‹¤": "ã‚¨ãƒ«ãƒ€ãƒ¼", "ê³ ë¬´ë‚˜ë¬´": "ã‚´ãƒ ãƒã‚­",
                            "ì‚¼ë‚˜ë¬´": "ã‚¹ã‚®", "ì°¸ì£½": "ãƒãƒ£ãƒ³ãƒãƒ¥ãƒ³", "ë‚´ì¶”ëŸ´": "ãƒŠãƒãƒ¥ãƒ©ãƒ«",
                            "ë„¤ì¶”ëŸ´": "ãƒŠãƒãƒ¥ãƒ©ãƒ«", "ì›Œì‹œ": "ã‚¦ã‚©ãƒƒã‚·ãƒ¥", "ë¹ˆí‹°ì§€": "ãƒ´ã‚£ãƒ³ãƒ†ãƒ¼ã‚¸",
                            "ì—”í‹±": "ã‚¢ãƒ³ãƒ†ã‚£ãƒ¼ã‚¯", "ìš°ë“œ": "ã‚¦ãƒƒãƒ‰", "ì• ì‰¬": "ã‚¢ãƒƒã‚·ãƒ¥",
                            "ìƒˆí‹´": "ã‚µãƒ†ãƒ³", "ë§ˆë¸”": "ãƒãƒ¼ãƒ–ãƒ«", "ë ˆë“œíŒŒì¸": "ãƒ¬ãƒƒãƒ‰ãƒ‘ã‚¤ãƒ³",
                            "ì§„": "ãƒ€ãƒ¼ã‚¯", "ì—°": "ãƒ©ã‚¤ãƒˆ", "ì˜¬": "ã‚ªãƒ¼ãƒ«", "ë¬´ë“œ": "ãƒ ãƒ¼ãƒ‰",
                            "ìŠ¤ì¹´ì´": "ã‚¹ã‚«ã‚¤", "ë² ì´ë¹„": "ãƒ™ãƒ“ãƒ¼", "ë¡œì¦ˆ": "ãƒ­ãƒ¼ã‚º",
                            "íŒŒìš°ë”": "ãƒ‘ã‚¦ãƒ€ãƒ¼", "ëª¨ë‹": "ãƒ¢ãƒ¼ãƒ‹ãƒ³ã‚°", "í‹¸": "ãƒ†ã‚£ãƒ¼ãƒ«",
                            "ìƒŒë“œ": "ã‚µãƒ³ãƒ‰", "ë©”íƒˆ": "ãƒ¡ã‚¿ãƒ«", "ë°”ìƒ¬íŠ¸": "ãƒã‚µãƒ«ãƒˆ",
                            "ì›œ": "ã‚¦ã‚©ãƒ¼ãƒ ", "ì°¨ì½œ": "ãƒãƒ£ã‚³ãƒ¼ãƒ«", "ì¸ë””": "ã‚¤ãƒ³ãƒ‡ã‚£",
                            "ë¡œíˆ¬ìŠ¤": "ãƒ­ãƒ¼ã‚¿ã‚¹", "ìŠ¤ëª¨í‚¤": "ã‚¹ãƒ¢ãƒ¼ã‚­ãƒ¼", "ë²„í„°": "ãƒã‚¿ãƒ¼",
                            "ìˆœë°±": "ç´”ç™½", "ìœ ë°±": "ä¹³ç™½"
                        }.get(modifier, modifier)
                        
                        if color_lower.startswith(modifier):
                            predicted_translation = f"{modifier_jp}{japanese_color}"
                        else:
                            predicted_translation = f"{japanese_color}{modifier_jp}"
                            
                        colors_in_glossary.append((color, count, predicted_translation))
                        found_in_glossary = True
                        break
                
                if found_in_glossary:
                    break
        
        if not found_in_glossary:
            colors_not_in_glossary.append((color, count))
    
    return {
        'total_colors': len(total_color_counter),
        'unique_colors': list(total_color_counter.keys()),
        'color_frequency': total_color_counter,
        'colors_by_column': color_stats,
        'colors_in_glossary': colors_in_glossary,
        'colors_not_in_glossary': colors_not_in_glossary,
        'glossary_coverage': len(colors_in_glossary) / max(1, len(total_color_counter)) * 100
    }

def suggest_glossary_additions(colors_not_in_glossary: List[tuple]) -> List[str]:
    """ìš©ì–´ì§‘ì— ì¶”ê°€í•  ìƒ‰ìƒ ì œì•ˆ"""
    suggestions = []
    
    # ìë™ ë²ˆì—­ ì œì•ˆ (ì¼ë°˜ì ì¸ ìƒ‰ìƒ íŒ¨í„´)
    auto_translations = {
        # ê·¸ë ˆì´ ê³„ì—´
        r'.*ê·¸ë ˆì´.*|.*ê·¸ë ˆ.*|.*íšŒìƒ‰.*': 'ã‚°ãƒ¬ãƒ¼',
        r'.*ë¼ì´íŠ¸.*ê·¸ë ˆ.*|.*ì—°.*íšŒìƒ‰.*': 'ãƒ©ã‚¤ãƒˆã‚°ãƒ¬ãƒ¼',
        r'.*ë‹¤í¬.*ê·¸ë ˆ.*|.*ì§„.*íšŒìƒ‰.*': 'ãƒ€ãƒ¼ã‚¯ã‚°ãƒ¬ãƒ¼',
        
        # ë² ì´ì§€/í¬ë¦¼ ê³„ì—´
        r'.*ë² ì´ì§€.*': 'ãƒ™ãƒ¼ã‚¸ãƒ¥',
        r'.*ì•„ì´ë³´ë¦¬.*': 'ã‚¢ã‚¤ãƒœãƒªãƒ¼',
        r'.*í¬ë¦¼.*': 'ã‚¯ãƒªãƒ¼ãƒ ',
        
        # ë„¤ì´ë¹„ ê³„ì—´
        r'.*ë„¤ì´ë¹„.*|.*ë‚¨ìƒ‰.*': 'ãƒã‚¤ãƒ“ãƒ¼',
        
        # ì¹´í‚¤/ì˜¬ë¦¬ë¸Œ ê³„ì—´
        r'.*ì¹´í‚¤.*': 'ã‚«ãƒ¼ã‚­',
        r'.*ì˜¬ë¦¬ë¸Œ.*': 'ã‚ªãƒªãƒ¼ãƒ–',
        
        # ì™€ì¸/ë²„ê±´ë”” ê³„ì—´
        r'.*ì™€ì¸.*': 'ãƒ¯ã‚¤ãƒ³',
        r'.*ë²„ê±´ë””.*': 'ãƒãƒ¼ã‚¬ãƒ³ãƒ‡ã‚£',
        
        # ë©”íƒˆ ê³„ì—´
        r'.*ê³¨ë“œ.*|.*ê¸ˆìƒ‰.*': 'ã‚´ãƒ¼ãƒ«ãƒ‰',
        r'.*ì‹¤ë²„.*|.*ì€ìƒ‰.*': 'ã‚·ãƒ«ãƒãƒ¼',
        r'.*ë©”íƒˆ.*': 'ãƒ¡ã‚¿ãƒªãƒƒã‚¯',
        
        # ê¸°íƒ€
        r'.*ì½”ë„.*': 'ã‚³ãƒ¼ãƒ©ãƒ«',
        r'.*ë¯¼íŠ¸.*': 'ãƒŸãƒ³ãƒˆ',
        r'.*ë¼ë²¤ë”.*': 'ãƒ©ãƒ™ãƒ³ãƒ€ãƒ¼',
        r'.*í„°ì½°ì´ì¦ˆ.*': 'ã‚¿ãƒ¼ã‚³ã‚¤ã‚º'
    }
    
    for color, count in colors_not_in_glossary:
        if count >= 2:  # 2íšŒ ì´ìƒ ë“±ì¥í•˜ëŠ” ìƒ‰ìƒ
            suggested_translation = None
            
            # ìë™ ë²ˆì—­ íŒ¨í„´ ë§¤ì¹­
            for pattern, translation in auto_translations.items():
                if re.match(pattern, color, re.IGNORECASE):
                    suggested_translation = translation
                    break
            
            if suggested_translation:
                suggestions.append(f"'{color}': '{suggested_translation}', # {count}íšŒ ë“±ì¥ (ìë™ ì œì•ˆ)")
            else:
                suggestions.append(f"'{color}': '(ë²ˆì—­ í•„ìš”)', # {count}íšŒ ë“±ì¥")
    
    return suggestions

def export_color_analysis_to_excel(analysis_result: Dict) -> bytes:
    """ìƒ‰ìƒ ë¶„ì„ ê²°ê³¼ë¥¼ ì—‘ì…€ë¡œ ë‚´ë³´ë‚´ê¸°"""
    import io
    import pandas as pd
    
    buffer = io.BytesIO()
    
    with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
        # ì „ì²´ ìƒ‰ìƒ ë¹ˆë„
        if analysis_result['color_frequency']:
            freq_df = pd.DataFrame(
                list(analysis_result['color_frequency'].items()),
                columns=['ìƒ‰ìƒëª…', 'ë¹ˆë„']
            ).sort_values('ë¹ˆë„', ascending=False)
            freq_df.to_excel(writer, sheet_name='ì „ì²´_ìƒ‰ìƒ_ë¹ˆë„', index=False)
        
        # ìš©ì–´ì§‘ì— ìˆëŠ” ìƒ‰ìƒ
        if analysis_result['colors_in_glossary']:
            glossary_df = pd.DataFrame(
                analysis_result['colors_in_glossary'],
                columns=['í•œêµ­ì–´', 'ë¹ˆë„', 'ì¼ë³¸ì–´']
            ).sort_values('ë¹ˆë„', ascending=False)
            glossary_df.to_excel(writer, sheet_name='ìš©ì–´ì§‘_ë“±ë¡_ìƒ‰ìƒ', index=False)
        
        # ìš©ì–´ì§‘ì— ì—†ëŠ” ìƒ‰ìƒ
        if analysis_result['colors_not_in_glossary']:
            missing_df = pd.DataFrame(
                analysis_result['colors_not_in_glossary'],
                columns=['ìƒ‰ìƒëª…', 'ë¹ˆë„']
            ).sort_values('ë¹ˆë„', ascending=False)
            missing_df.to_excel(writer, sheet_name='ìš©ì–´ì§‘_ë¯¸ë“±ë¡_ìƒ‰ìƒ', index=False)
        
        # ì»¬ëŸ¼ë³„ ë¶„ì„
        for col, color_counter in analysis_result['colors_by_column'].items():
            if color_counter:
                col_df = pd.DataFrame(
                    list(color_counter.items()),
                    columns=['ìƒ‰ìƒëª…', 'ë¹ˆë„']
                ).sort_values('ë¹ˆë„', ascending=False)
                sheet_name = f"ì»¬ëŸ¼_{col.replace('ì˜µì…˜ì…ë ¥', '')}"[:31]  # ì—‘ì…€ ì‹œíŠ¸ëª… ê¸¸ì´ ì œí•œ
                col_df.to_excel(writer, sheet_name=sheet_name, index=False)
    
    return buffer.getvalue()

def translate_option_column(df, column_name: str, api_key: str, target_lang: str = 'JA'):
    """ì˜µì…˜ ì»¬ëŸ¼ ë²ˆì—­ (ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜)"""
    def translate_option_row(option_text):
        return translate_option_colors(option_text, api_key, target_lang)
    
    df[column_name] = df[column_name].apply(translate_option_row)
    return df

async def translate_option_column_batch_old(df, target_column: str, api_key: str, 
                                      batch_size: int = 5, use_async: bool = True):
    """ì˜µì…˜ ì»¬ëŸ¼ ë°°ì¹˜ ë²ˆì—­ (ìƒí’ˆëª… ë²ˆì—­ê³¼ ë™ì¼í•œ ë°©ì‹)"""
    
    # ëŒ€í­ í™•ì¥ëœ ìƒ‰ìƒ ë§¤í•‘ í…Œì´ë¸” (API í˜¸ì¶œ ìµœì†Œí™”)
    color_map = {
        # ê¸°ë³¸ ìƒ‰ìƒ
        'í™”ì´íŠ¸': 'ãƒ›ãƒ¯ã‚¤ãƒˆ', 'ë¸”ë™': 'ãƒ–ãƒ©ãƒƒã‚¯', 'ê·¸ë ˆì´': 'ã‚°ãƒ¬ãƒ¼',
        'ì—°ê·¸ë ˆì´': 'ãƒ©ã‚¤ãƒˆã‚°ãƒ¬ãƒ¼', 'ì§„ê·¸ë ˆì´': 'ãƒ€ãƒ¼ã‚¯ã‚°ãƒ¬ãƒ¼',
        'ë² ì´ì§€': 'ãƒ™ãƒ¼ã‚¸ãƒ¥', 'ë¸Œë¼ìš´': 'ãƒ–ãƒ©ã‚¦ãƒ³', 'ë„¤ì´ë¹„': 'ãƒã‚¤ãƒ“ãƒ¼',
        'ì˜¤í¬': 'ã‚ªãƒ¼ã‚¯', 'ë©”ì´í”Œ': 'ãƒ¡ãƒ¼ãƒ—ãƒ«', 'ì•„ì¹´ì‹œì•„': 'ã‚¢ã‚«ã‚·ã‚¢',
        'ì›”ë„›': 'ã‚¦ã‚©ãƒ«ãƒŠãƒƒãƒˆ', 'ë©€ë°”ìš°': 'ãƒ¡ãƒ«ãƒã‚¦', 'í¬ë¦¼': 'ã‚¯ãƒªãƒ¼ãƒ ',
        'ì•„ì´ë³´ë¦¬': 'ã‚¢ã‚¤ãƒœãƒªãƒ¼', 'ì¹´í‚¤': 'ã‚«ãƒ¼ã‚­', 'ì˜¬ë¦¬ë¸Œ': 'ã‚ªãƒªãƒ¼ãƒ–',
        'ë¯¼íŠ¸': 'ãƒŸãƒ³ãƒˆ', 'ë¼ë²¤ë”': 'ãƒ©ãƒ™ãƒ³ãƒ€ãƒ¼', 'ê³¨ë“œ': 'ã‚´ãƒ¼ãƒ«ãƒ‰',
        'ì‹¤ë²„': 'ã‚·ãƒ«ãƒãƒ¼', 'ë ˆë“œ': 'ãƒ¬ãƒƒãƒ‰', 'ë¸”ë£¨': 'ãƒ–ãƒ«ãƒ¼',
        'ê·¸ë¦°': 'ã‚°ãƒªãƒ¼ãƒ³', 'ì˜ë¡œìš°': 'ã‚¤ã‚¨ãƒ­ãƒ¼', 'í•‘í¬': 'ãƒ”ãƒ³ã‚¯',
        
        # ë³µí•© ìƒ‰ìƒ (ë¡œê·¸ì—ì„œ ìì£¼ ë‚˜íƒ€ë‚˜ëŠ” ìƒ‰ìƒë“¤)
        'ì˜¤í¬í™”ì´íŠ¸': 'ã‚ªãƒ¼ã‚¯ãƒ›ãƒ¯ã‚¤ãƒˆ', 'í¬ë¦¼í™”ì´íŠ¸': 'ã‚¯ãƒªãƒ¼ãƒ ãƒ›ãƒ¯ã‚¤ãƒˆ',
        'ë„¤ì¶”ëŸ´': 'ãƒŠãƒãƒ¥ãƒ©ãƒ«', 'ë„¤ì¶”ëŸ´ë©€ë°”ìš°': 'ãƒŠãƒãƒ¥ãƒ©ãƒ«ãƒ¡ãƒ«ãƒã‚¦',
        'ë„¤ì¶”ëŸ´í”¼ì¹˜': 'ãƒŠãƒãƒ¥ãƒ©ãƒ«ãƒ”ãƒ¼ãƒ', 'ë„¤ì¶”ëŸ´ë¸”ë£¨': 'ãƒŠãƒãƒ¥ãƒ©ãƒ«ãƒ–ãƒ«ãƒ¼',
        'í™”ì´íŠ¸ë©”ì´í”Œ': 'ãƒ›ãƒ¯ã‚¤ãƒˆãƒ¡ãƒ¼ãƒ—ãƒ«', 'í™”ì´íŠ¸ê·¸ë ˆì´': 'ãƒ›ãƒ¯ã‚¤ãƒˆã‚°ãƒ¬ãƒ¼',
        'í™”ì´íŠ¸ì˜¤í¬': 'ãƒ›ãƒ¯ã‚¤ãƒˆã‚ªãƒ¼ã‚¯', 'ë‹¤í¬ë¸Œë¼ìš´': 'ãƒ€ãƒ¼ã‚¯ãƒ–ãƒ©ã‚¦ãƒ³',
        'ë¼ì´íŠ¸ë¸Œë¼ìš´': 'ãƒ©ã‚¤ãƒˆãƒ–ãƒ©ã‚¦ãƒ³', 'ë”¥ë¸Œë¼ìš´': 'ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ–ãƒ©ã‚¦ãƒ³',
        
        # ìì£¼ ì‚¬ìš©ë˜ëŠ” ë³µí•© ìƒ‰ìƒë“¤ ì¶”ê°€
        'ê·¸ë ˆì´ë¸”ë™': 'ã‚°ãƒ¬ãƒ¼ãƒ–ãƒ©ãƒƒã‚¯', 'ì°¸ì£½': 'ãƒãƒ£ãƒ³ãƒãƒ¥ãƒ³', 'íˆ¬í†¤': 'ãƒ„ãƒ¼ãƒˆãƒ³',
        'ëª¨ì¹´ë¸Œë¼ìš´': 'ãƒ¢ã‚«ãƒ–ãƒ©ã‚¦ãƒ³', 'ë²„ê±´ë””': 'ãƒãƒ¼ã‚¬ãƒ³ãƒ‡ã‚£', 'íŒŒìš°ë”ë¸”ë£¨': 'ãƒ‘ã‚¦ãƒ€ãƒ¼ãƒ–ãƒ«ãƒ¼',
        'ë¡œíˆ¬ìŠ¤í•‘í¬': 'ãƒ­ãƒ¼ã‚¿ã‚¹ãƒ”ãƒ³ã‚¯', 'ë„¤ì¶”ëŸ´í™”ì´íŠ¸': 'ãƒŠãƒãƒ¥ãƒ©ãƒ«ãƒ›ãƒ¯ã‚¤ãƒˆ',
        'ì•„ì´ë³´ë¦¬ë©”ì´í”Œ': 'ã‚¢ã‚¤ãƒœãƒªãƒ¼ãƒ¡ãƒ¼ãƒ—ãƒ«', 'ì›Œì‹œê·¸ë¦°': 'ã‚¦ã‚©ãƒƒã‚·ãƒ¥ã‚°ãƒªãƒ¼ãƒ³',
        'ë¸”ë™ì•„ì¹´ì‹œì•„': 'ãƒ–ãƒ©ãƒƒã‚¯ã‚¢ã‚«ã‚·ã‚¢', 'ê·¸ë ˆì´ë©”ì´í”Œ': 'ã‚°ãƒ¬ãƒ¼ãƒ¡ãƒ¼ãƒ—ãƒ«',
        'ì»¤í”¼': 'ã‚³ãƒ¼ãƒ’ãƒ¼', 'ë² ì´ì§€ë¸Œë¼ìš´': 'ãƒ™ãƒ¼ã‚¸ãƒ¥ãƒ–ãƒ©ã‚¦ãƒ³', 'ëª¨ì¹´': 'ãƒ¢ã‚«',
        'ì˜¤ë Œì§€': 'ã‚ªãƒ¬ãƒ³ã‚¸', 'ì—°í•‘í¬': 'ãƒ©ã‚¤ãƒˆãƒ”ãƒ³ã‚¯', 'ë¼ì´íŠ¸ê·¸ë ˆì´': 'ãƒ©ã‚¤ãƒˆã‚°ãƒ¬ãƒ¼',
        'ì›œê·¸ë ˆì´': 'ã‚¦ã‚©ãƒ¼ãƒ ã‚°ãƒ¬ãƒ¼', 'ìƒŒë“œë² ì´ì§€': 'ã‚µãƒ³ãƒ‰ãƒ™ãƒ¼ã‚¸ãƒ¥', 'ì–´í”„ë¦¬ì½§': 'ã‚¢ãƒ—ãƒªã‚³ãƒƒãƒˆ',
        'ë ˆëª¬': 'ãƒ¬ãƒ¢ãƒ³', 'ëŒ€ë¦¬ì„': 'å¤§ç†çŸ³', 'íˆ¬ëª…': 'é€æ˜', 'ì—˜ë‹¤': 'ã‚¨ãƒ«ãƒ€ãƒ¼',
        'í¬ë ˆìŠ¤íŠ¸ê·¸ë¦°': 'ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã‚°ãƒªãƒ¼ãƒ³', 'ìƒŒë“œê·¸ë ˆì´': 'ã‚µãƒ³ãƒ‰ã‚°ãƒ¬ãƒ¼',
        'ìƒˆí‹´ê·¸ë ˆì´': 'ã‚µãƒ†ãƒ³ã‚°ãƒ¬ãƒ¼', 'ë°”ìƒ¬íŠ¸ê·¸ë ˆì´': 'ãƒã‚µãƒ«ãƒˆã‚°ãƒ¬ãƒ¼',
        'ì°¨ì½œê·¸ë ˆì´': 'ãƒãƒ£ã‚³ãƒ¼ãƒ«ã‚°ãƒ¬ãƒ¼', 'ë©”íƒˆê·¸ë ˆì´': 'ãƒ¡ã‚¿ãƒ«ã‚°ãƒ¬ãƒ¼',
        'ë¹ˆí‹°ì§€ê·¸ë ˆì´': 'ãƒ´ã‚£ãƒ³ãƒ†ãƒ¼ã‚¸ã‚°ãƒ¬ãƒ¼', 'í˜ì¼ê·¸ë ˆì´': 'ãƒšãƒ¼ãƒ«ã‚°ãƒ¬ãƒ¼',
        'ë‹¤í¬ê·¸ë ˆì´': 'ãƒ€ãƒ¼ã‚¯ã‚°ãƒ¬ãƒ¼', 'ì—°íšŒìƒ‰': 'ãƒ©ã‚¤ãƒˆã‚°ãƒ¬ãƒ¼',
        'ë¬´ë“œë¸”ë™': 'ãƒ ãƒ¼ãƒ‰ãƒ–ãƒ©ãƒƒã‚¯', 'ì°¨ì½œë¸”ë™': 'ãƒãƒ£ã‚³ãƒ¼ãƒ«ãƒ–ãƒ©ãƒƒã‚¯',
        'ë¡œì¦ˆê³¨ë“œ': 'ãƒ­ãƒ¼ã‚ºã‚´ãƒ¼ãƒ«ãƒ‰', 'ë¬´ê´‘ì‹¤ë²„': 'ãƒãƒƒãƒˆã‚·ãƒ«ãƒãƒ¼',
        'ìœ ê´‘ì‹¤ë²„': 'ã‚°ãƒ­ãƒƒã‚·ãƒ¼ã‚·ãƒ«ãƒãƒ¼', 'ì„¸ë¼ë¯¹': 'ã‚»ãƒ©ãƒŸãƒƒã‚¯',
        'ì›ëª©': 'ç„¡å¢æ', 'ë‚´ì¶”ëŸ´': 'ãƒŠãƒãƒ¥ãƒ©ãƒ«', 'ì›Œì‹œ': 'ã‚¦ã‚©ãƒƒã‚·ãƒ¥',
        'ë¹ˆí‹°ì§€': 'ãƒ´ã‚£ãƒ³ãƒ†ãƒ¼ã‚¸', 'ì—”í‹±': 'ã‚¢ãƒ³ãƒ†ã‚£ãƒ¼ã‚¯', 'ìƒˆí‹´': 'ã‚µãƒ†ãƒ³',
        'ë§ˆë¸”': 'ãƒãƒ¼ãƒ–ãƒ«', 'ë©”íƒˆ': 'ãƒ¡ã‚¿ãƒ«', 'ìš°ë“œ': 'ã‚¦ãƒƒãƒ‰'
    }
    
    def process_option_text(option_text):
        """ì˜µì…˜ í…ìŠ¤íŠ¸ ì²˜ë¦¬ í•¨ìˆ˜"""
        if pd.isna(option_text) or not str(option_text).strip():
            return option_text
        
        text = str(option_text).strip()
        
        # ìƒ‰ìƒ{...} í˜•ì‹ì´ ì•„ë‹ˆë©´ ì›ë³¸ ë°˜í™˜
        if not text.startswith('ìƒ‰ìƒ{') or not text.endswith('}'):
            return text
        
        try:
            # ìƒ‰ìƒ ì¶”ì¶œ
            colors_part = text[3:-1]  # 'ìƒ‰ìƒ{' ì™€ '}' ì œê±°
            colors = [c.strip() for c in colors_part.split('|') if c.strip()]
            
            # ë¹ˆ ê´„í˜¸ì¸ ê²½ìš° ì›ë³¸ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ)
            if not colors:
                print(f"ë¹ˆ ì˜µì…˜ ë°œê²¬, ì›ë³¸ ìœ ì§€: {text}")
                return text
            
            # ë§¤í•‘ í…Œì´ë¸”ì— ìˆëŠ” ìƒ‰ìƒê³¼ ì—†ëŠ” ìƒ‰ìƒ ë¶„ë¦¬
            mapped_colors = []
            api_needed_colors = []
            color_indices = []
            
            for i, color in enumerate(colors):
                if color in color_map:
                    mapped_colors.append((i, color_map[color]))
                else:
                    api_needed_colors.append(color)
                    color_indices.append(i)
            
            return {
                'original': text,
                'colors': colors,
                'mapped_colors': mapped_colors,
                'api_needed_colors': api_needed_colors,
                'color_indices': color_indices
            }
        except Exception as e:
            print(f"ì˜µì…˜ ì²˜ë¦¬ ì˜¤ë¥˜: {text}, ì—ëŸ¬: {str(e)}")
            return text
    
    # ëª¨ë“  ì˜µì…˜ í…ìŠ¤íŠ¸ ì²˜ë¦¬
    texts = df[target_column].fillna("").astype(str).tolist()
    processed_data = [process_option_text(text) for text in texts]
    
    # API ë²ˆì—­ì´ í•„ìš”í•œ ìƒ‰ìƒë“¤ ìˆ˜ì§‘
    all_api_colors = []
    for data in processed_data:
        if isinstance(data, dict) and 'api_needed_colors' in data:
            all_api_colors.extend(data['api_needed_colors'])
    
    # ì¤‘ë³µ ì œê±°
    unique_api_colors = list(set(all_api_colors))
    
    # API ë²ˆì—­ ì‹¤í–‰ (429 ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•œ ì œí•œëœ ì²˜ë¦¬)
    if unique_api_colors:
        print(f"API ë²ˆì—­ í•„ìš”í•œ ìƒ‰ìƒ ìˆ˜: {len(unique_api_colors)}")
        
        # 429 ì—ëŸ¬ ë°©ì§€: API ë²ˆì—­ì„ ì œí•œí•˜ê³  ëŒ€ë¶€ë¶„ ì›ë³¸ ìœ ì§€
        api_translation_dict = {}
        
        if len(unique_api_colors) > 100:
            print(f"âš ï¸ API ë²ˆì—­ í•„ìš”í•œ ìƒ‰ìƒì´ {len(unique_api_colors)}ê°œë¡œ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤.")
            print("429 ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ API ë²ˆì—­ì„ ê±´ë„ˆë›°ê³  ì›ë³¸ ìƒ‰ìƒì„ ìœ ì§€í•©ë‹ˆë‹¤.")
            print("ë§¤í•‘ í…Œì´ë¸”ì— ìì£¼ ì‚¬ìš©ë˜ëŠ” ìƒ‰ìƒì„ ì¶”ê°€í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        else:
            print(f"API ë²ˆì—­ ì‹œë„: {unique_api_colors[:10]}...")  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥
            
            # ì†ŒëŸ‰ì˜ ìƒ‰ìƒë§Œ API ë²ˆì—­ ì‹œë„
            if use_async:
                translated_api_colors = await translate_batch_async_with_deepl(
                    unique_api_colors, api_key, batch_size=2  # ë°°ì¹˜ í¬ê¸°ë¥¼ 2ë¡œ ì¤„ì„
                )
            else:
                translated_api_colors = translate_batch_with_deepl(
                    unique_api_colors, api_key, batch_size=2
                )
            
            # ë²ˆì—­ ê²°ê³¼ ë¶„ì„
            successful_translations = 0
            failed_translations = 0
            
            # ë²ˆì—­ ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (ë¹ˆ ê²°ê³¼ í•„í„°ë§)
            for original, translated in zip(unique_api_colors, translated_api_colors):
                # ë²ˆì—­ ê²°ê³¼ê°€ ìœ íš¨í•œ ê²½ìš°ë§Œ ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€
                if translated and translated.strip():
                    api_translation_dict[original] = translated
                    successful_translations += 1
                else:
                    failed_translations += 1
                    # ì‹¤íŒ¨í•œ ìƒ‰ìƒì€ ë¡œê·¸ë§Œ ì¶œë ¥ (ë„ˆë¬´ ë§ì•„ì„œ ì¼ë¶€ë§Œ)
                    if failed_translations <= 10:
                        print(f"ë²ˆì—­ ì‹¤íŒ¨: '{original}' -> '{translated}'")
            
            print(f"ë²ˆì—­ ì„±ê³µ: {successful_translations}ê°œ, ì‹¤íŒ¨: {failed_translations}ê°œ")
    else:
        api_translation_dict = {}
        print("API ë²ˆì—­ì´ í•„ìš”í•œ ìƒ‰ìƒì´ ì—†ìŠµë‹ˆë‹¤ (ëª¨ë‘ ë§¤í•‘ í…Œì´ë¸”ì— ìˆìŒ)")
    
    # ìµœì¢… ê²°ê³¼ ì¡°í•©
    final_results = []
    for data in processed_data:
        if isinstance(data, str):
            # ì²˜ë¦¬ë˜ì§€ ì•Šì€ í…ìŠ¤íŠ¸ (ìƒ‰ìƒ í˜•ì‹ì´ ì•„ë‹˜)
            final_results.append(data)
        elif isinstance(data, dict):
            # ìƒ‰ìƒ í˜•ì‹ í…ìŠ¤íŠ¸
            colors = data['colors'][:]
            
            # ë§¤í•‘ëœ ìƒ‰ìƒ ì ìš©
            for idx, translated in data['mapped_colors']:
                colors[idx] = translated
            
            # API ë²ˆì—­ëœ ìƒ‰ìƒ ì ìš© (ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë³´ì¡´)
            for i, original_idx in enumerate(data['color_indices']):
                original_color = data['api_needed_colors'][i]
                if original_color in api_translation_dict:
                    translated_color = api_translation_dict[original_color]
                    # ë²ˆì—­ ê²°ê³¼ê°€ ìœ íš¨í•œ ê²½ìš°ë§Œ ì ìš©, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ì›ë³¸ ìœ ì§€
                    if translated_color and translated_color.strip():
                        colors[original_idx] = translated_color
                    else:
                        # ë²ˆì—­ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ìƒ‰ìƒ ëª…ì‹œì ìœ¼ë¡œ ìœ ì§€
                        colors[original_idx] = original_color
                else:
                    # API ë²ˆì—­ ë”•ì…”ë„ˆë¦¬ì— ì—†ëŠ” ê²½ìš° (ê±´ë„ˆë›´ ê²½ìš°) ì›ë³¸ ìƒ‰ìƒ ìœ ì§€
                    colors[original_idx] = original_color
            
            # ìµœì¢… ì˜µì…˜ í…ìŠ¤íŠ¸ êµ¬ì„± (ë¹ˆ ìƒ‰ìƒ í•„í„°ë§)
            valid_colors = [color for color in colors if color and color.strip()]
            if valid_colors:
                final_results.append(f"ìƒ‰ìƒ{{{'|'.join(valid_colors)}}}")
            else:
                # ëª¨ë“  ìƒ‰ìƒì´ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš° ì›ë³¸ ë°˜í™˜
                print(f"âš ï¸ ëª¨ë“  ìƒ‰ìƒì´ ë¹ˆ ë¬¸ìì—´: {data['original']}")
                print(f"   ì›ë³¸ ìƒ‰ìƒë“¤: {data['colors']}")
                print(f"   ì²˜ë¦¬ëœ ìƒ‰ìƒë“¤: {colors}")
                print(f"   ë§¤í•‘ëœ ìƒ‰ìƒë“¤: {data['mapped_colors']}")
                print(f"   API í•„ìš” ìƒ‰ìƒë“¤: {data['api_needed_colors']}")
                final_results.append(data['original'])
        else:
            final_results.append(data)
    
    return final_results