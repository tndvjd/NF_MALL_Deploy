import pandas as pd
import streamlit as st
from typing import Iterator, Callable, Any, Optional, Dict, List
import time
from functools import wraps
import gc

class ChunkProcessor:
    """ì²­í¬ ë‹¨ìœ„ ë°ì´í„° ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, chunk_size: int = 1000, show_progress: bool = True):
        self.chunk_size = chunk_size
        self.show_progress = show_progress
        self.processed_chunks = 0
        self.total_chunks = 0
        self.start_time = None
    
    def process_dataframe_in_chunks(
        self, 
        df: pd.DataFrame, 
        process_func: Callable[[pd.DataFrame], pd.DataFrame],
        **kwargs
    ) -> pd.DataFrame:
        """ë°ì´í„°í”„ë ˆì„ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬"""
        
        if len(df) <= self.chunk_size:
            # ì‘ì€ ë°ì´í„°ëŠ” ì²­í¬ ì²˜ë¦¬ ì—†ì´ ë°”ë¡œ ì²˜ë¦¬
            return process_func(df, **kwargs)
        
        self.total_chunks = (len(df) + self.chunk_size - 1) // self.chunk_size
        self.processed_chunks = 0
        self.start_time = time.time()
        
        processed_chunks = []
        
        # Streamlit ì§„í–‰ë¥  í‘œì‹œ
        if self.show_progress:
            progress_bar = st.progress(0)
            status_text = st.empty()
            time_text = st.empty()
        
        try:
            for i in range(0, len(df), self.chunk_size):
                chunk = df.iloc[i:i + self.chunk_size].copy()
                
                # ì²­í¬ ì²˜ë¦¬
                processed_chunk = process_func(chunk, **kwargs)
                processed_chunks.append(processed_chunk)
                
                self.processed_chunks += 1
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                if self.show_progress:
                    progress = self.processed_chunks / self.total_chunks
                    progress_bar.progress(progress)
                    
                    # ìƒíƒœ í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
                    status_text.text(
                        f"ì²˜ë¦¬ ì¤‘: {self.processed_chunks:,}/{self.total_chunks:,} ì²­í¬ "
                        f"({i + len(chunk):,}/{len(df):,} í–‰)"
                    )
                    
                    # ì˜ˆìƒ ì™„ë£Œ ì‹œê°„ ê³„ì‚°
                    if self.processed_chunks > 1:
                        elapsed_time = time.time() - self.start_time
                        avg_time_per_chunk = elapsed_time / self.processed_chunks
                        remaining_chunks = self.total_chunks - self.processed_chunks
                        estimated_remaining = avg_time_per_chunk * remaining_chunks
                        
                        time_text.text(
                            f"ê²½ê³¼ ì‹œê°„: {elapsed_time:.1f}ì´ˆ, "
                            f"ì˜ˆìƒ ì™„ë£Œ: {estimated_remaining:.1f}ì´ˆ í›„"
                        )
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                del chunk
                if i % (self.chunk_size * 5) == 0:  # 5ì²­í¬ë§ˆë‹¤ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
                    gc.collect()
            
            # ê²°ê³¼ í•©ì¹˜ê¸°
            result_df = pd.concat(processed_chunks, ignore_index=True)
            
            if self.show_progress:
                progress_bar.progress(1.0)
                total_time = time.time() - self.start_time
                status_text.text(f"âœ… ì™„ë£Œ: {len(df):,}í–‰ ì²˜ë¦¬ ì™„ë£Œ ({total_time:.1f}ì´ˆ)")
                time_text.empty()
            
            return result_df
            
        except Exception as e:
            if self.show_progress:
                st.error(f"ì²­í¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise e
        
        finally:
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            del processed_chunks
            gc.collect()
    
    def process_file_in_chunks(
        self,
        file_path: str,
        process_func: Callable[[pd.DataFrame], pd.DataFrame],
        output_path: Optional[str] = None,
        **kwargs
    ) -> pd.DataFrame:
        """íŒŒì¼ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ì½ì–´ì„œ ì²˜ë¦¬"""
        
        try:
            # íŒŒì¼ í¬ê¸° í™•ì¸
            file_size = pd.read_excel(file_path, nrows=0).shape[0]  # í—¤ë”ë§Œ ì½ì–´ì„œ êµ¬ì¡° í™•ì¸
            
            if self.show_progress:
                st.info(f"ğŸ“ íŒŒì¼ ì²­í¬ ì²˜ë¦¬ ì‹œì‘: {file_path}")
            
            processed_chunks = []
            chunk_reader = pd.read_excel(file_path, chunksize=self.chunk_size)
            
            self.processed_chunks = 0
            self.start_time = time.time()
            
            # ì§„í–‰ë¥  í‘œì‹œ ì¤€ë¹„
            if self.show_progress:
                progress_bar = st.progress(0)
                status_text = st.empty()
            
            for chunk_num, chunk in enumerate(chunk_reader):
                # ì²­í¬ ì²˜ë¦¬
                processed_chunk = process_func(chunk, **kwargs)
                processed_chunks.append(processed_chunk)
                
                self.processed_chunks += 1
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (ì •í™•í•œ ì´ ì²­í¬ ìˆ˜ë¥¼ ëª¨ë¥´ë¯€ë¡œ ê·¼ì‚¬ì¹˜ ì‚¬ìš©)
                if self.show_progress:
                    status_text.text(
                        f"ì²˜ë¦¬ ì¤‘: {self.processed_chunks}ë²ˆì§¸ ì²­í¬ "
                        f"({len(chunk):,}í–‰ ì²˜ë¦¬)"
                    )
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                del chunk
                if chunk_num % 5 == 0:
                    gc.collect()
            
            # ê²°ê³¼ í•©ì¹˜ê¸°
            result_df = pd.concat(processed_chunks, ignore_index=True)
            
            if self.show_progress:
                total_time = time.time() - self.start_time
                status_text.text(f"âœ… íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: {len(result_df):,}í–‰ ({total_time:.1f}ì´ˆ)")
            
            # ê²°ê³¼ ì €ì¥ (ì„ íƒì‚¬í•­)
            if output_path:
                result_df.to_excel(output_path, index=False)
                if self.show_progress:
                    st.success(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
            
            return result_df
            
        except Exception as e:
            if self.show_progress:
                st.error(f"íŒŒì¼ ì²­í¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise e
        
        finally:
            del processed_chunks
            gc.collect()
    
    def split_dataframe_into_chunks(self, df: pd.DataFrame) -> List[pd.DataFrame]:
        """ë°ì´í„°í”„ë ˆì„ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• """
        chunks = []
        
        for i in range(0, len(df), self.chunk_size):
            chunk = df.iloc[i:i + self.chunk_size].copy()
            chunks.append(chunk)
        
        return chunks

def chunk_processing_decorator(chunk_size: int = 1000, show_progress: bool = True):
    """ì²­í¬ ì²˜ë¦¬ ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        @wraps(func)
        def wrapper(df: pd.DataFrame, *args, **kwargs):
            # ì²­í¬ ì²˜ë¦¬ê°€ í•„ìš”í•œì§€ í™•ì¸
            if len(df) <= chunk_size:
                return func(df, *args, **kwargs)
            
            # ì²­í¬ ì²˜ë¦¬ ì‹¤í–‰
            processor = ChunkProcessor(chunk_size=chunk_size, show_progress=show_progress)
            return processor.process_dataframe_in_chunks(df, func, *args, **kwargs)
        
        return wrapper
    return decorator

def estimate_processing_time(df: pd.DataFrame, sample_size: int = 100) -> Dict[str, float]:
    """ì²˜ë¦¬ ì‹œê°„ ì˜ˆìƒ"""
    if len(df) <= sample_size:
        return {'estimated_time': 0, 'sample_time': 0, 'scaling_factor': 1}
    
    # ìƒ˜í”Œ ë°ì´í„°ë¡œ ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
    sample_df = df.head(sample_size).copy()
    
    start_time = time.time()
    # ê°„ë‹¨í•œ ì²˜ë¦¬ ì‘ì—… (ì˜ˆ: ë°ì´í„° ë³µì‚¬)
    _ = sample_df.copy()
    sample_time = time.time() - start_time
    
    # ì „ì²´ ë°ì´í„° ì²˜ë¦¬ ì‹œê°„ ì˜ˆìƒ
    scaling_factor = len(df) / sample_size
    estimated_time = sample_time * scaling_factor
    
    return {
        'estimated_time': estimated_time,
        'sample_time': sample_time,
        'scaling_factor': scaling_factor
    }

def recommend_chunk_size(df: pd.DataFrame, target_memory_mb: float = 50) -> int:
    """ì ì ˆí•œ ì²­í¬ í¬ê¸° ì¶”ì²œ"""
    # ë°ì´í„°í”„ë ˆì„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì •
    memory_per_row = df.memory_usage(deep=True).sum() / len(df) / (1024 * 1024)  # MB per row
    
    # ëª©í‘œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì— ë§ëŠ” ì²­í¬ í¬ê¸° ê³„ì‚°
    recommended_size = int(target_memory_mb / memory_per_row)
    
    # ìµœì†Œ 100í–‰, ìµœëŒ€ 10000í–‰ìœ¼ë¡œ ì œí•œ
    recommended_size = max(100, min(10000, recommended_size))
    
    return recommended_size

def display_chunk_info(df: pd.DataFrame, chunk_size: int):
    """ì²­í¬ ì²˜ë¦¬ ì •ë³´ í‘œì‹œ"""
    total_chunks = (len(df) + chunk_size - 1) // chunk_size
    memory_usage = df.memory_usage(deep=True).sum() / (1024 * 1024)  # MB
    
    st.info(
        f"ğŸ“Š ì²­í¬ ì²˜ë¦¬ ì •ë³´:\n"
        f"â€¢ ì „ì²´ ë°ì´í„°: {len(df):,}í–‰\n"
        f"â€¢ ì²­í¬ í¬ê¸°: {chunk_size:,}í–‰\n"
        f"â€¢ ì´ ì²­í¬ ìˆ˜: {total_chunks:,}ê°œ\n"
        f"â€¢ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_usage:.1f}MB"
    )
    
    # ì²˜ë¦¬ ì‹œê°„ ì˜ˆìƒ
    time_estimate = estimate_processing_time(df)
    if time_estimate['estimated_time'] > 0:
        st.info(
            f"â±ï¸ ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: {time_estimate['estimated_time']:.1f}ì´ˆ"
        )

# ì²­í¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def safe_chunk_processing(func):
    """ì•ˆì „í•œ ì²­í¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except MemoryError:
            st.error("âŒ ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ì²˜ë¦¬ë¥¼ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤. ì²­í¬ í¬ê¸°ë¥¼ ì¤„ì—¬ì£¼ì„¸ìš”.")
            raise
        except Exception as e:
            st.error(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise
    return wrapper